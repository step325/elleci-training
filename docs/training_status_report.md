# Elleci V1 - Training Status Report

**Data**: 2026-01-12  
**Obiettivo**: Training di un modello LLM da 1.5B parametri su 12GB VRAM (RTX 4070)

---

## Architettura Modello

### Configurazione Attuale

| Parametro | Valore | Note |
|-----------|--------|------|
| **Dimensione modello** | 2048d Ã— 24L | ~1.5B parametri |
| **Vocabolario** | 32,128 token | Rounded da 32,043 |
| **Sequenza max** | 1024 token | Con curriculum learning |
| **Batch size** | 2 | Ridotto per VRAM |
| **Gradient accumulation** | 32 | Effective batch = 64 |
| **Precisione** | bfloat16 | Mixed precision |

### Architettura Ibrida

1. **Mamba-2 (SSD)** - State Space Model per sequenze lunghe
   - `chunk_size`: 64
   - `d_state`: 8 (ridotto da 16)
   - `n_heads`: 8
   
2. **MLA (Multi-head Latent Attention)** - KV cache compression
   - Alternato con Mamba nei layer

3. **BitNet 1.58b** - Ternary weights per efficienza

4. **Router** - Adaptive Fast/Slow paths (opzionale)

---

## Tecnologie Implementate

### âœ… Ottimizzazioni Attive

| Tecnologia | Stato | Risparmio/Beneficio |
|------------|-------|---------------------|
| **LION Optimizer** | ğŸ¦ Attivo | -50% optimizer state vs AdamW |
| **Gradient Checkpointing** | âœ… Attivo | ~90% risparmio attivazioni |
| **BFloat16** | âœ… Attivo | -50% memoria pesi/attivazioni |
| **LeRaC** | âœ… Attivo | Per-layer LR curriculum |
| **WSD Scheduler** | âœ… Attivo | Warmup-Stable-Decay |
| **Lazy SWA** | âœ… Attivo | Inizializza a step 40k |
| **Buffered Dataset** | âœ… Attivo | 500 samples pre-loaded |
| **Curriculum Learning** | âœ… Attivo | 256 â†’ 1024 token |

### âŒ Ottimizzazioni Provate ma Scartate

| Tecnologia | Stato | Motivo |
|------------|-------|--------|
| **Liger Kernel Fused CE** | âŒ Fallito | Triton CUDA error con vocab 32128 + bf16 |
| **torch.compile** | âŒ Rimosso | Overhead invece di speedup |
| **8-bit AdamW** | â¸ï¸ Sostituito | Sostituito da LION |

### ğŸ”„ Ottimizzazioni in Test

| Tecnologia | Stato | Note |
|------------|-------|------|
| **Liger Kernel** | ğŸ”„ Disabilitato temp | Test LION senza overhead Triton |

---

## Uso Memoria

### VRAM Dedicata (12.88 GB disponibili)

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           VRAM BREAKDOWN                 â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ Pesi modello:          5.05 GB         â•‘
â•‘ Gradienti:             5.05 GB         â•‘
â•‘ Optimizer (LION):      ~1.25 GB        â•‘  â† Step 32+
â•‘ Attivazioni (ckpt):    0.02 GB         â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ TOTALE STIMATO:       ~11.4 GB         â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

**Status**: âš ï¸ **Overflow di ~0.5-1.5 GB â†’ Shared Memory**

### Memoria Condivisa (System RAM DDR5 6000MT/s)

- **Step 0-31**: ~1.0 - 1.3 GB
- **Step 32+**: ~1.5 - 4.0 GB (dopo optimizer.step())
- **Impatto**: ~10-15x piÃ¹ lenta di VRAM dedicata

---

## Performance

### VelocitÃ  Training

| Fase | s/it | tokens/sec | Memoria Condivisa | Note |
|------|------|------------|-------------------|------|
| **Step 0-30** | ~4s | ~128 | ~1.0 GB | Prima optimizer.step() |
| **Step 32-40** | ~15s | ~34 | ~3-4 GB | Primo optimizer.step (LION) |
| **Step 42+** | ~19s | ~27 | **5.9 GB** | Crescita progressiva âš ï¸ |

**Test in corso (2026-01-12 22:02)**: LION + Liger disabilitato

### Rallentamenti Identificati

1. **Shared Memory Access** - Principale bottleneck
   - Crescita progressiva: 1.0 GB â†’ 5.9 GB a step 42
   - Impatto: 4s/it â†’ 19s/it (~5x rallentamento)
   
2. **Memory Leak Persistente** 
   - Anche con tutte le ottimizzazioni applicate
   - LION non ha risolto completamente il problema
   
3. **Mamba-2 Python loops** - Chunk iteration (~48 loop/forward)
4. **Dataset refill** - Background threads disabilitati per leak

---

## Problemi Risolti

### 1. ModuleNotFoundError: scripts.benchmark_chimera
**Soluzione**: Commentato import non utilizzato

### 2. Dataset Loading Error (wikipedia trust_remote_code)
**Soluzione**: Aggiornato a `wikimedia/wikipedia` (Parquet)

### 3. Data Loading Bottleneck (121s/it)
**Soluzione**: Implementato buffered dataset con pre-loading
- **Risultato**: 121s â†’ 18-22s/it

### 4. VRAM Over-allocation (15.43 GB su 12.88 GB)
**Soluzioni applicate**:
- Ridotto batch_size: 16 â†’ 8 â†’ 4 â†’ 2
- Aumentato grad_accum: 4 â†’ 8 â†’ 16 â†’ 32
- Lazy SWA initialization
- `torch.cuda.empty_cache()` periodico
- **Risultato**: 15.43 GB â†’ ~11-12 GB (con overflow tollerabile)

### 5. Memory Leak (RAM condivisa crescente)
**Soluzioni applicate**:
- Disabilitato background refill
- Ridotto buffer: 2000 â†’ 500 samples
- `optimizer.zero_grad(set_to_none=True)`
- Periodic `gc.collect()`
- **Risultato**: Crescita rallentata ma non eliminata

### 6. Liger Kernel CUDA Illegal Memory Access
**Causa**: vocab_size 32128 (non power-of-2) + bf16 + Triton
**Soluzione**: Disabilitato fused CE, mantenuto standard cross-entropy

---

## Problemi Aperti

### ğŸ”´ Critici

1. **Shared Memory Usage**
   - Causa: Modello 1.5B troppo grande per 12GB VRAM
   - Impatto: Rallentamento 10-15x su ~1-4GB di dati
   - Opzioni:
     - âœ… Accettare e ottimizzare (strategia corrente)
     - âŒ Ridurre modello a ~800M (rifiutato)
     - ğŸ”„ Ottimizzare LION + rimuovere overhead

2. **Training Speed (15-25s/it)**
   - Target: <10s/it
   - Attuale: ~40-70 tokens/sec
   - Causa principale: Shared memory access
   
### âš ï¸ Da Monitorare

1. **LION Optimizer** - In test, deve provare convergenza
2. **Liger Kernel** - Potenziale speedup se risolto bug Triton
3. **Mamba-2 Loops** - Possibile ottimizzazione vettorizzazione

---

## Configurazione Training

### Optimizer: LION

```python
lr = 3.0e-5  # 10x piÃ¹ basso di AdamW
weight_decay = 0.1  # 10x piÃ¹ alto
# Solo momentum, no variance â†’ -50% memory
```

### Scheduler: WSD + LeRaC

- **Warmup**: 1000 steps
- **Stable**: Step 1000-45000
- **Decay**: Step 45000-50000
- **Per-layer LR**: Layer piÃ¹ profondi â†’ LR piÃ¹ alte

### Dataset Mix

| Fonte | Ratio | Samples Buffer |
|-------|-------|----------------|
| en_cosmo | 55% | 500 |
| it_wiki | 35% | 499 |
| it_instruct | 10% | 164 |

---

## Prossimi Passi

### Immediati

1. âœ… **Test LION senza Liger** - Verificare stabilitÃ  memoria
2. â³ **Lasciare training fino a step 50+** - Confermare convergenza
3. ğŸ”„ **Monitorare shared memory** - Deve restare <3GB

### Se Training Stabile

1. **Re-abilitare Liger** (altri kernel, non fused CE)
   - RMSNorm
   - SwiGLU
   - Proiezioni lineari

2. **Profiling dettagliato**
   - Identificare altri bottleneck
   - Ottimizzare Mamba-2 ulteriormente

3. **Considerare GaLore** se LION non sufficiente

### Alternative Radicali (se necessario)

1. **DeepSpeed ZeRO-2/3** - Offload optimizer a CPU/NVMe
2. **Model Parallelism** - Split model su piÃ¹ GPU
3. **Cloud Training** - AWS p4d/p5 instances (40-80GB VRAM)

---

## Hardware Setup

| Componente | Spec |
|------------|------|
| **GPU** | NVIDIA GeForce RTX 4070 |
| **VRAM** | 12.88 GB GDDR6X (~500 GB/s) |
| **RAM** | 32 GB DDR5 6000MT/s (~48 GB/s) |
| **PCIe** | 4.0 x16 (~32 GB/s) |
| **OS** | WSL2 (Ubuntu on Windows) |
| **Python** | 3.10 (conda env: elleci) |
| **PyTorch** | 2.x (CUDA 12.1) |

---

## Conclusioni

### âœ… Successi

- Modello 1.5B **funziona** su 12GB VRAM (con compromessi)
- Pipeline dati efficiente (~500 samples buffered)
- Architettura ibrida Mamba/MLA implementata
- Ottimizzazioni memoria applicate con successo

### âš ï¸ Compromessi Necessari

- **Shared memory usage**: ~1-4 GB inevitabile
- **VelocitÃ  ridotta**: ~40-70 tokens/sec invece di 100+
- **Batch size minimo**: 2 (effective 64 con grad_accum)

### ğŸ¯ Strategia Finale

**Accettare il bottleneck shared memory** e ottimizzare il resto:
- LION optimizer per minimizzare overflow
- Liger kernel (se fixato) per velocitÃ 
- Monitorare convergenza sul lungo periodo (50k steps)

Il training **funzionerÃ **, ma sarÃ  piÃ¹ lento del desiderato. Per velocitÃ  ottimale serve GPU con 16+ GB VRAM.

---

*Report generato il 2026-01-12 alle 21:57*
